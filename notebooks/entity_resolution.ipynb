{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573232d",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport recordlinkage\nfrom recordlinkage.index import Block\nimport networkx as nx\nfrom collections import defaultdict\nimport time\n\nstart = time.time()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88ba0b",
   "metadata": {},
   "outputs": [],
   "source": "df = pd.read_csv(\"../data/customers_raw.csv\")\nprint(f\"Loaded {len(df):,} records\")\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "1a11fd46",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779d297a",
   "metadata": {},
   "outputs": [],
   "source": "df_clean = df.copy()\n\ndf_clean['first_name_clean'] = df_clean['first_name'].str.lower().str.strip()\ndf_clean['last_name_clean'] = df_clean['last_name'].str.lower().str.strip()\ndf_clean['email_username'] = df_clean['email'].str.split('@').str[0].str.lower()\ndf_clean['phone_clean'] = df_clean['phone'].astype(str).str.replace('-', '').str.replace('None', '')\n\ndf_clean['block_key'] = (\n    df_clean['last_name_clean'].str[:3] + '_' + \n    df_clean['first_name_clean'].str[:1] + '_' + \n    df_clean['province'].fillna('')\n)\n\nprint(f\"Created {df_clean['block_key'].nunique():,} blocks\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab15d5",
   "metadata": {},
   "outputs": [],
   "source": "block_sizes = df_clean['block_key'].value_counts()\nblock_sizes.describe()"
  },
  {
   "cell_type": "markdown",
   "id": "463f4c56",
   "metadata": {},
   "source": [
    "### Cell blocking and candidate pair generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c43ed5",
   "metadata": {},
   "outputs": [],
   "source": "df_clean = df_clean.set_index('record_id')\n\nblock_sizes = df_clean['block_key'].value_counts()\nMAX_BLOCK_SIZE = 2000\n\nvalid_blocks = block_sizes[block_sizes <= MAX_BLOCK_SIZE].index.tolist()\ndf_filtered = df_clean[df_clean['block_key'].isin(valid_blocks)]\n\nindexer = recordlinkage.Index()\nindexer.block('block_key')\ncandidate_pairs = indexer.index(df_filtered)\n\nprint(f\"Valid blocks: {len(valid_blocks):,} | Records: {len(df_filtered):,} | Candidate pairs: {len(candidate_pairs):,}\")"
  },
  {
   "cell_type": "markdown",
   "id": "3e299a51",
   "metadata": {},
   "source": [
    "### Similarity comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0418da0",
   "metadata": {},
   "outputs": [],
   "source": "compare = recordlinkage.Compare()\ncompare.exact('phone_clean', 'phone_clean', label='phone_exact')\ncompare.exact('email_username', 'email_username', label='email_exact')\ncompare.string('first_name_clean', 'first_name_clean', method='jarowinkler', label='first_name_sim')\ncompare.string('last_name_clean', 'last_name_clean', method='jarowinkler', label='last_name_sim')\ncompare.exact('date_of_birth', 'date_of_birth', label='dob_exact')\n\nCHUNK_SIZE = 1_000_000\nall_features = []\n\nfor i in range(0, len(candidate_pairs), CHUNK_SIZE):\n    chunk_pairs = candidate_pairs[i:i+CHUNK_SIZE]\n    chunk_features = compare.compute(chunk_pairs, df_filtered)\n    all_features.append(chunk_features)\n\nfeatures = pd.concat(all_features)\ndel all_features\n\nprint(f\"Computed {len(features):,} comparisons\")\nfeatures.describe()"
  },
  {
   "cell_type": "markdown",
   "id": "27ea44a1",
   "metadata": {},
   "source": [
    "### Classify Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3df36e",
   "metadata": {},
   "outputs": [],
   "source": "features['total_score'] = (\n    features['phone_exact'] * 3.0 +\n    features['email_exact'] * 3.0 +\n    features['first_name_sim'] * 1.0 +\n    features['last_name_sim'] * 1.0 +\n    features['dob_exact'] * 2.0\n)\n\nTHRESHOLD = 7.0\nmatches = features[features['total_score'] >= THRESHOLD]\n\nprint(f\"Found {len(matches):,} matches (threshold={THRESHOLD})\")"
  },
  {
   "cell_type": "markdown",
   "id": "b9a11cfc",
   "metadata": {},
   "source": [
    "### Build graph and find clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accc700",
   "metadata": {},
   "outputs": [],
   "source": "G = nx.Graph()\nG.add_nodes_from(df_filtered.index)\nG.add_edges_from(matches.index.tolist())\n\ncomponents = list(nx.connected_components(G))\nprint(f\"Edges: {G.number_of_edges():,} | Unique customers: {len(components):,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002eb16",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\n\ninteresting_clusters = [c for c in components if 2 <= len(c) <= 10][:5]\n\nfig, axes = plt.subplots(1, min(5, len(interesting_clusters)), figsize=(15, 4))\n\nif len(interesting_clusters) == 1:\n    axes = [axes]\n\nfor idx, cluster in enumerate(interesting_clusters):\n    subgraph = G.subgraph(cluster)\n    ax = axes[idx]\n    pos = nx.spring_layout(subgraph, seed=42)\n    nx.draw(subgraph, pos, ax=ax, with_labels=True, node_color='lightblue',\n            node_size=500, font_size=6, font_weight='bold', edge_color='gray')\n    ax.set_title(f\"Cluster {idx+1} ({len(cluster)} records)\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "9d3b787c",
   "metadata": {},
   "source": [
    "### Assign resolved IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec9a21",
   "metadata": {},
   "outputs": [],
   "source": "record_to_cluster = {}\nfor cluster_id, component in enumerate(components):\n    for record_id in component:\n        record_to_cluster[record_id] = f\"CUST_{cluster_id:07d}\"\n\ndf_filtered = df_filtered.copy()\ndf_filtered['resolved_customer_id'] = df_filtered.index.map(record_to_cluster)\n\nprint(f\"Resolved {len(df_filtered):,} records to {df_filtered['resolved_customer_id'].nunique():,} customers\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e37589",
   "metadata": {},
   "outputs": [],
   "source": "df_truth_indexed = df_truth.set_index('record_id')\ndf_filtered['true_customer_id'] = df_truth_indexed.loc[df_filtered.index, 'true_customer_id']\n\npurity_check = df_filtered.groupby('resolved_customer_id')['true_customer_id'].nunique()\nperfect = (purity_check == 1).sum()\ntotal_clusters = len(purity_check)\n\nfrag_check = df_filtered.groupby('true_customer_id')['resolved_customer_id'].nunique()\nfragmented = (frag_check > 1).sum()\n\nprint(f\"Purity: {perfect:,}/{total_clusters:,} ({perfect/total_clusters*100:.1f}%) | Fragmented: {fragmented:,}\")"
  },
  {
   "cell_type": "markdown",
   "id": "03d68248",
   "metadata": {},
   "source": [
    "### Save the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc8ed7",
   "metadata": {},
   "outputs": [],
   "source": "output_df = df_filtered.reset_index()\noutput_df.to_csv('../data/customer_data_cleaned.csv')\n\nprint(f\"Saved: {len(output_df):,} records, {output_df['resolved_customer_id'].nunique():,} customers\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}