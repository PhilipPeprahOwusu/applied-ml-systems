{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "DATA_DIR = '../../data'\n",
    "CUSTOMERS_FILE = os.path.join(DATA_DIR, 'customers_with_truth.csv')\n",
    "OUTPUT_TRANSACTIONS_FILE = os.path.join(DATA_DIR, 'transactions.csv')\n",
    "OUTPUT_INTERACTIONS_FILE = os.path.join(DATA_DIR, 'offer_interactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service offerings\n",
    "services = [\n",
    "    {'service_id': 'SRV001', 'name': 'Oil Change', 'base_price': 49.99, 'category': 'Maintenance'},\n",
    "    {'service_id': 'SRV002', 'name': 'Tire Rotation', 'base_price': 29.99, 'category': 'Maintenance'},\n",
    "    {'service_id': 'SRV003', 'name': 'Brake Inspection', 'base_price': 39.99, 'category': 'Maintenance'},\n",
    "    {'service_id': 'SRV004', 'name': 'Full Detail', 'base_price': 149.99, 'category': 'Cosmetic'},\n",
    "    {'service_id': 'SRV005', 'name': 'Windshield Repair', 'base_price': 79.99, 'category': 'Repair'},\n",
    "    {'service_id': 'SRV006', 'name': 'Battery Replacement', 'base_price': 129.99, 'category': 'Repair'},\n",
    "    {'service_id': 'SRV007', 'name': 'AC Service', 'base_price': 89.99, 'category': 'Maintenance'},\n",
    "    {'service_id': 'SRV008', 'name': 'Transmission Flush', 'base_price': 179.99, 'category': 'Maintenance'},\n",
    "    {'service_id': 'SRV009', 'name': 'Wheel Alignment', 'base_price': 99.99, 'category': 'Maintenance'},\n",
    "    {'service_id': 'SRV010', 'name': 'Engine Diagnostic', 'base_price': 69.99, 'category': 'Diagnostic'},\n",
    "]\n",
    "\n",
    "# Offers - base_rate now has WIDER spread\n",
    "offers = [\n",
    "    {'offer_id': 'OFF001', 'name': 'Free Oil Change', 'type': 'Free Service', 'value': 49.99, 'base_rate': 0.30},\n",
    "    {'offer_id': 'OFF002', 'name': '20% Off Any Service', 'type': 'Discount', 'value': 0.20, 'base_rate': 0.25},\n",
    "    {'offer_id': 'OFF003', 'name': 'Loyalty Points 2X', 'type': 'Points', 'value': 2.0, 'base_rate': 0.10},\n",
    "    {'offer_id': 'OFF004', 'name': '$25 Off Next Visit', 'type': 'Credit', 'value': 25.00, 'base_rate': 0.28},\n",
    "    {'offer_id': 'OFF005', 'name': 'Free Tire Rotation', 'type': 'Free Service', 'value': 29.99, 'base_rate': 0.32},\n",
    "    {'offer_id': 'OFF006', 'name': 'Winter Package Deal', 'type': 'Bundle', 'value': 50.00, 'base_rate': 0.15},\n",
    "    {'offer_id': 'OFF007', 'name': 'Refer a Friend $50', 'type': 'Referral', 'value': 50.00, 'base_rate': 0.08},\n",
    "    {'offer_id': 'OFF008', 'name': 'Birthday Special 30%', 'type': 'Discount', 'value': 0.30, 'base_rate': 0.35},\n",
    "]\n",
    "\n",
    "locations = ['Edmonton South', 'Edmonton North', 'Calgary Downtown', 'Calgary NE',\n",
    "             'Red Deer', 'Lethbridge', 'Vancouver', 'Surrey', 'Winnipeg', 'Saskatoon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "np.random.seed(42)\nrandom.seed(42)\n\ndf_customers = pd.read_csv(CUSTOMERS_FILE)\ncustomer_ids = df_customers['true_customer_id'].unique()\nn_customers = len(customer_ids)\nprint(f\"Loaded {n_customers:,} unique customers\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "transactions = []\ntransaction_id = 0\n\ncustomer_segments = np.random.choice(\n    ['occasional', 'regular', 'frequent', 'vip'], \n    size=n_customers, \n    p=[0.35, 0.40, 0.18, 0.07]\n)\nsegment_map = dict(zip(customer_ids, customer_segments))\n\nfor idx, customer_id in enumerate(customer_ids):\n    segment = segment_map[customer_id]\n    \n    if segment == 'occasional': \n        n_trans = np.random.randint(1, 3)\n    elif segment == 'regular': \n        n_trans = np.random.randint(4, 10)\n    elif segment == 'frequent':\n        n_trans = np.random.randint(10, 18)\n    else:\n        n_trans = np.random.randint(18, 30)\n    \n    preferred_location = random.choice(locations)\n    preferred_category = random.choice(['Maintenance', 'Repair', 'Cosmetic', 'Diagnostic'])\n    spending_tier = np.random.choice(['budget', 'standard', 'premium'], p=[0.30, 0.50, 0.20])\n    \n    base_date = datetime(2024, 1, 1)\n    \n    if segment in ['frequent', 'vip']:\n        max_recency = 180\n    elif segment == 'regular':\n        max_recency = 400\n    else:\n        max_recency = 800\n    \n    for i in range(n_trans):\n        if i == 0:\n            days_ago = random.randint(0, max_recency)\n        else:\n            days_ago = random.randint(0, 1095)\n        \n        trans_date = base_date - timedelta(days=days_ago)\n        \n        if random.random() < 0.65:\n            preferred_services = [s for s in services if s['category'] == preferred_category]\n            service = random.choice(preferred_services) if preferred_services else random.choice(services)\n        else:\n            service = random.choice(services)\n        \n        if spending_tier == 'budget':\n            price_mult = random.uniform(0.75, 0.95)\n        elif spending_tier == 'premium':\n            price_mult = random.uniform(1.05, 1.30)\n        else:\n            price_mult = random.uniform(0.90, 1.10)\n        \n        price = service['base_price'] * price_mult\n        location = preferred_location if random.random() < 0.7 else random.choice(locations)\n        \n        transactions.append({\n            'transaction_id': f\"TXN{transaction_id:08d}\",\n            'customer_id': customer_id,\n            'service_id': service['service_id'],\n            'service_name': service['name'],\n            'service_category': service['category'],\n            'amount': round(price, 2),\n            'location': location,\n            'transaction_date': trans_date.strftime('%Y-%m-%d'),\n            'transaction_time': f\"{random.randint(8,18):02d}:{random.randint(0,59):02d}:00\"\n        })\n        transaction_id += 1\n\ndf_transactions = pd.DataFrame(transactions)\nprint(f\"Generated {len(df_transactions):,} transactions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compute Customer Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_transactions['transaction_date'] = pd.to_datetime(df_transactions['transaction_date'])\nREFERENCE_DATE = pd.to_datetime('2024-01-01')\n\ncustomer_features = df_transactions.groupby('customer_id').agg(\n    frequency=('transaction_id', 'count'),\n    monetary_total=('amount', 'sum'),\n    monetary_avg=('amount', 'mean'),\n    monetary_std=('amount', 'std'),\n    last_purchase=('transaction_date', 'max'),\n    first_purchase=('transaction_date', 'min'),\n    unique_services=('service_id', 'nunique'),\n    unique_categories=('service_category', 'nunique'),\n    unique_locations=('location', 'nunique')\n).reset_index()\n\ncustomer_features['recency_days'] = (REFERENCE_DATE - customer_features['last_purchase']).dt.days\ncustomer_features['tenure_days'] = (customer_features['last_purchase'] - customer_features['first_purchase']).dt.days\ncustomer_features['monetary_std'] = customer_features['monetary_std'].fillna(0)\n\ncustomer_features['avg_days_between'] = customer_features['tenure_days'] / customer_features['frequency'].clip(lower=1)\ncustomer_features['is_one_time'] = (customer_features['frequency'] == 1).astype(int)\ncustomer_features['is_high_spender'] = (customer_features['monetary_avg'] > customer_features['monetary_avg'].quantile(0.75)).astype(int)\ncustomer_features['is_recent'] = (customer_features['recency_days'] <= 60).astype(int)\ncustomer_features['is_frequent'] = (customer_features['frequency'] >= 8).astype(int)\n\ncustomer_features = customer_features.drop(columns=['last_purchase', 'first_purchase'])\ncustomer_feature_dict = customer_features.set_index('customer_id').to_dict('index')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Generate Offers with STRONG Signal\n",
    "\n",
    "Key: Create **wide separation** in redemption probabilities based on observable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_redemption_prob_v4(customer_id, offer, customer_feature_dict):\n",
    "    \"\"\"\n",
    "    STRONG signal version - creates wide probability spread (5% to 70%)\n",
    "    \"\"\"\n",
    "    feat = customer_feature_dict.get(customer_id, {})\n",
    "    \n",
    "    # Start with offer base rate\n",
    "    prob = offer['base_rate']\n",
    "    \n",
    "    frequency = feat.get('frequency', 1)\n",
    "    recency = feat.get('recency_days', 500)\n",
    "    monetary_avg = feat.get('monetary_avg', 80)\n",
    "    is_one_time = feat.get('is_one_time', 1)\n",
    "    unique_services = feat.get('unique_services', 1)\n",
    "    offer_type = offer['type']\n",
    "    offer_value = offer['value']\n",
    "    \n",
    "    if frequency >= 15:\n",
    "        prob += 0.30  # VIP customers: massive boost\n",
    "    elif frequency >= 10:\n",
    "        prob += 0.22\n",
    "    elif frequency >= 6:\n",
    "        prob += 0.14\n",
    "    elif frequency >= 3:\n",
    "        prob += 0.06\n",
    "    elif frequency == 1:\n",
    "        prob -= 0.12  # One-timers: significant penalty\n",
    "    \n",
    "    # RECENCY: Strong impact\n",
    "    if recency <= 14:\n",
    "        prob += 0.20  # Very recent: big boost\n",
    "    elif recency <= 30:\n",
    "        prob += 0.15\n",
    "    elif recency <= 60:\n",
    "        prob += 0.10\n",
    "    elif recency <= 90:\n",
    "        prob += 0.05\n",
    "    elif recency > 365:\n",
    "        prob -= 0.15  # Lapsed: significant penalty\n",
    "    elif recency > 180:\n",
    "        prob -= 0.08\n",
    "    \n",
    "    # MONETARY: Moderate impact\n",
    "    if monetary_avg > 130:\n",
    "        prob += 0.08 \n",
    "    elif monetary_avg > 100:\n",
    "        prob += 0.04\n",
    "    elif monetary_avg < 50:\n",
    "        prob -= 0.05\n",
    "    \n",
    "    if unique_services >= 6:\n",
    "        prob += 0.08\n",
    "    elif unique_services >= 4:\n",
    "        prob += 0.04\n",
    "    \n",
    "\n",
    "    # DISCOUNT offers\n",
    "    if offer_type == 'Discount':\n",
    "        if monetary_avg < 70:  \n",
    "            prob += 0.18\n",
    "        elif monetary_avg < 90:\n",
    "            prob += 0.10\n",
    "        elif monetary_avg > 130:  \n",
    "            prob -= 0.08\n",
    "        \n",
    "        # Recent + discount = action\n",
    "        if recency <= 30:\n",
    "            prob += 0.08\n",
    "    \n",
    "    # FREE SERVICE offers\n",
    "    elif offer_type == 'Free Service':\n",
    "        if monetary_avg > 100:\n",
    "            prob += 0.15\n",
    "        else:\n",
    "            prob += 0.08\n",
    "        \n",
    "        # Frequent customers more likely to use it\n",
    "        if frequency >= 5:\n",
    "            prob += 0.10\n",
    "    \n",
    "    # POINTS offers - ONLY work for frequent customers\n",
    "    elif offer_type == 'Points':\n",
    "        if frequency >= 12:\n",
    "            prob += 0.35  # Loyalists love points\n",
    "        elif frequency >= 8:\n",
    "            prob += 0.20\n",
    "        elif frequency >= 5:\n",
    "            prob += 0.08\n",
    "        else:\n",
    "            prob -= 0.15  \n",
    "    # BUNDLE offers - need commitment\n",
    "    elif offer_type == 'Bundle':\n",
    "        if frequency >= 8 and monetary_avg > 90:\n",
    "            prob += 0.20  \n",
    "        elif frequency >= 5:\n",
    "            prob += 0.08\n",
    "        elif frequency <= 2:\n",
    "            prob -= 0.18  \n",
    "    \n",
    "    # REFERRAL - only satisfied frequent customers refer\n",
    "    elif offer_type == 'Referral':\n",
    "        if frequency >= 10 and recency <= 90:\n",
    "            prob += 0.25  \n",
    "        elif frequency >= 6 and recency <= 180:\n",
    "            prob += 0.10\n",
    "        else:\n",
    "            prob -= 0.12  \n",
    "    \n",
    "    # CREDIT offers\n",
    "    elif offer_type == 'Credit':\n",
    "        \n",
    "        if frequency >= 4 and recency <= 120:\n",
    "            prob += 0.15\n",
    "        elif recency > 365:\n",
    "            prob -= 0.10  \n",
    "    \n",
    "    if offer_value >= 50:\n",
    "        prob += 0.05  \n",
    "    elif offer_value >= 25:\n",
    "        prob += 0.02\n",
    "    \n",
    "    return max(0.03, min(0.75, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "offer_interactions = []\ninteraction_id = 0\nredemption_probs_log = []\n\nfor idx, customer_id in enumerate(customer_ids):\n    feat = customer_feature_dict.get(customer_id, {})\n    frequency = feat.get('frequency', 1)\n    \n    if frequency >= 12:\n        n_offers = random.randint(8, 15)\n    elif frequency >= 6:\n        n_offers = random.randint(5, 10)\n    elif frequency >= 3:\n        n_offers = random.randint(3, 7)\n    else:\n        n_offers = random.randint(2, 5)\n    \n    for _ in range(n_offers):\n        offer = random.choice(offers)\n        days_ago = random.randint(0, 730)\n        sent_date = datetime(2024, 1, 1) - timedelta(days=days_ago)\n        \n        redeem_prob = calculate_redemption_prob_v4(customer_id, offer, customer_feature_dict)\n        redemption_probs_log.append(redeem_prob)\n        \n        open_rate = 0.60 + min(0.25, frequency * 0.02)\n        opened = random.random() < open_rate\n        \n        click_rate = 0.45 + min(0.20, frequency * 0.015)\n        clicked = opened and random.random() < click_rate\n        \n        redeemed = clicked and random.random() < redeem_prob\n        \n        offer_interactions.append({\n            'interaction_id': f\"INT{interaction_id:08d}\",\n            'customer_id': customer_id,\n            'offer_id': offer['offer_id'],\n            'offer_name': offer['name'],\n            'offer_type': offer['type'],\n            'offer_value': offer['value'],\n            'sent_date': sent_date.strftime('%Y-%m-%d'),\n            'opened': int(opened),\n            'clicked': int(clicked),\n            'redeemed': int(redeemed)\n        })\n        interaction_id += 1\n\ndf_offers = pd.DataFrame(offer_interactions)\nprint(f\"Generated {len(df_offers):,} offer interactions\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Verify STRONG Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"Redemption prob range: {np.min(redemption_probs_log):.2f} - {np.max(redemption_probs_log):.2f} (std={np.std(redemption_probs_log):.2f})\")\nprint(f\"Redemption rate: {df_offers['redeemed'].mean()*100:.1f}%\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_analysis = df_offers.merge(\n    customer_features[['customer_id', 'frequency', 'recency_days', 'monetary_avg']], \n    on='customer_id'\n)\n\ndf_analysis['freq_bin'] = pd.cut(\n    df_analysis['frequency'], \n    bins=[0, 2, 5, 10, 15, 100], \n    labels=['1-2', '3-5', '6-10', '11-15', '15+']\n)\n\nfreq_stats = df_analysis.groupby('freq_bin')['redeemed'].agg(['mean', 'count'])\nfreq_stats['rate_%'] = (freq_stats['mean'] * 100).round(1)\nfreq_stats[['rate_%', 'count']]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_analysis['recency_bin'] = pd.cut(\n    df_analysis['recency_days'], \n    bins=[0, 30, 90, 180, 365, 2000], \n    labels=['0-30d', '31-90d', '91-180d', '181-365d', '365d+']\n)\n\nrecency_stats = df_analysis.groupby('recency_bin')['redeemed'].agg(['mean', 'count'])\nrecency_stats['rate_%'] = (recency_stats['mean'] * 100).round(1)\nrecency_stats[['rate_%', 'count']]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "offer_stats = df_analysis.groupby('offer_type')['redeemed'].agg(['mean', 'count'])\noffer_stats['rate_%'] = (offer_stats['mean'] * 100).round(1)\noffer_stats.sort_values('rate_%', ascending=False)[['rate_%', 'count']]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "points_analysis = df_analysis[df_analysis['offer_type'] == 'Points']\npoints_by_freq = points_analysis.groupby('freq_bin')['redeemed'].mean() * 100\npoints_by_freq.round(1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_analysis['monetary_bin'] = pd.cut(\n    df_analysis['monetary_avg'], \n    bins=[0, 70, 100, 130, 500], \n    labels=['<$70', '$70-100', '$100-130', '$130+']\n)\ndiscount_analysis = df_analysis[df_analysis['offer_type'] == 'Discount']\ndiscount_by_monetary = discount_analysis.groupby('monetary_bin')['redeemed'].mean() * 100\ndiscount_by_monetary.round(1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cross = pd.crosstab(\n    df_analysis['offer_type'], \n    df_analysis['freq_bin'], \n    values=df_analysis['redeemed'], \n    aggfunc='mean'\n).round(3) * 100\ncross.round(1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df_transactions['transaction_date'] = df_transactions['transaction_date'].dt.strftime('%Y-%m-%d')\n\nos.makedirs(DATA_DIR, exist_ok=True)\ndf_transactions.to_csv(OUTPUT_TRANSACTIONS_FILE, index=False)\ndf_offers.to_csv(OUTPUT_INTERACTIONS_FILE, index=False)\n\nprint(f\"Saved: {OUTPUT_TRANSACTIONS_FILE}, {OUTPUT_INTERACTIONS_FILE}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f\"Transactions: {len(df_transactions):,} | Offers: {len(df_offers):,} | Redemption: {df_offers['redeemed'].mean()*100:.1f}%\")\nprint(f\"Signal: freq {freq_stats['rate_%'].min():.1f}%-{freq_stats['rate_%'].max():.1f}% | recency {recency_stats['rate_%'].min():.1f}%-{recency_stats['rate_%'].max():.1f}%\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}